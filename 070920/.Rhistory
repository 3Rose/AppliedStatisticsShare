#a) Perform a Principal Component Analysis of the dataset, evaluate whether it is appropriate to use the original
#variables or the standardized ones and proceed accordingly. Report a plot of the loadings of the first 3 principal
#components and interpret them.
weather <- read.table('weather.txt')
head(weather)
pcs <- princomp(weather)
pcs
S <- cov(weather)
barplot(S)
boxplot(weather)
boxplot(weather, las=2)
S
S[5,5]
S[7,7]
#bene standardizzare
pcs <- princomp((weather-mean(weather))/sd(weather))
mean(weather)
colMeans(weather)
#bene standardizzare
pcs <- princomp((weather-colMeans(weather))/sd(weather))
(weather-colMeans(weather))
(weather-colMeans(weather))/sd(weather)
sd(weather)
diag(cov(weather))
help(diag)
diag(cov(weather),8,8)
#alta differenza tra le varianze della variabile 5  e variabile 7
V <- sqrt(diag(as.vector(diag(cov(weather))), nrow=8,ncol=8))
V
cov(weather)
#alta differenza tra le varianze della variabile 5  e variabile 7
Vmezzi <- sqrt(diag(as.vector(diag(cov(weather))), nrow=8,ncol=8))
#bene standardizzare
pcs <- princomp(solve(Vmezzi)%*%(weather-colMeans(weather)))
solve(Vmezzi)
#bene standardizzare
pcs <- princomp(as.matrix(solve(Vmezzi))%*%(weather-colMeans(weather)))
#bene standardizzare
pcs <- princomp(as.matrix(solve(Vmezzi))%*%cbind(weather-colMeans(weather)))
as.matrix(solve(Vmezzi))
Vmezzi
dim(weather)
as.matrix(solve(Vmezzi))%*%cbind(weather-colMeans(weather))
#bene standardizzare
std_weather <- scale(weather)
std_weather
head(std_weather)
pc.weather <- princomp(std_weather)
pc.weather
summary(pc.weather)
barplot(pc.weather$loadings)
plot(pc.weather)
pc.weather$loadings
length(pc.weather$loadings)
barplot(pc.weather$loadings[,i])
for(i in 1:8)
barplot(pc.weather$loadings[,i])
x11()
par(mfrow = c(4,2))
for(i in 1:8)
barplot(pc.weather$loadings[,i])
pc.weather$loadings
x11()
par(mfrow = c(4,2))
for(i in 1:8)
barplot(pc.weather$loadings[,i], main = 'component '+i)
x11()
par(mfrow = c(4,2))
for(i in 1:8)
barplot(pc.weather$loadings[,i], main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(4,2))
for(i in 1:8)
barplot(pc.weather$loadings[,i], main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], ylim= c(-1,1), main = paste('component ',i, sep = ''))
barplot(pc.weather$loadings[,i], ylim= c(-1,1), las=2, main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], ylim= c(-1,1), las=2, main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], ylim= c(-0.8,1), las=2, main = paste('component ',i, sep = ''))
pc.weather$scores
plot(pc.weather$scores[,1], pc.weather$scores[,2])
abline(v = 0)
abline(h = 0)
#b) Report the scatter plot of the data along the first two principal components and describe how to interpret the
#four quadrants of the plane. Use the information about the day of the year to further interpret the results.
plot(pc.weather$scores[,1], pc.weather$scores[,2], col=rep(c(2,3,4,5), each= 91))
abline(v = 0)
abline(h = 0)
#b) Report the scatter plot of the data along the first two principal components and describe how to interpret the
#four quadrants of the plane. Use the information about the day of the year to further interpret the results.
plot(pc.weather$scores[,1], pc.weather$scores[,2], col=rep(c('blue','green','red','gold'), each= 91))
abline(v = 0)
abline(h = 0)
#b) Report the scatter plot of the data along the first two principal components and describe how to interpret the
#four quadrants of the plane. Use the information about the day of the year to further interpret the results.
plot(pc.weather$scores[,1], pc.weather$scores[,2], col=rep(c('blue','green','red','gold'), each= 213/4))
abline(v = 0)
abline(h = 0)
x11()
par(mfrow = c(1,3))
for(i in 1:3)
barplot(pc.weather$loadings[,i], ylim= c(-1,1), las=2, main = paste('component ',i, sep = ''))
x11()
par(mfrow = c(4,2))
for(i in 1:8)
barplot(pc.weather$loadings[,i], main = paste('component ',i, sep = ''))
#b) Report the scatter plot of the data along the first two principal components and describe how to interpret the
#four quadrants of the plane. Use the information about the day of the year to further interpret the results.
plot(pc.weather$scores[,1], pc.weather$scores[,2], col=rep(c('blue','red'), each= 213/2))
abline(v = 0)
abline(h = 0)
#c) Report the screeplot. Propose (with motivations) a dimensionality reduction of the dataset. Report the variance
#explained along the principal components retained.
plot(cumsum(pc.weather$sdev^2)/sum(pc.weather$sdev^2))
#c) Report the screeplot. Propose (with motivations) a dimensionality reduction of the dataset. Report the variance
#explained along the principal components retained.
plot(cumsum(pc.weather$sdev^2)/sum(pc.weather$sdev^2), type = 'l')
#c) Report the screeplot. Propose (with motivations) a dimensionality reduction of the dataset. Report the variance
#explained along the principal components retained.
plot(cumsum(pc.weather$sdev^2)/sum(pc.weather$sdev^2), type = 'b')
abline(h = 0.9)
#c) Report the screeplot. Propose (with motivations) a dimensionality reduction of the dataset. Report the variance
#explained along the principal components retained.
plot(cumsum(pc.weather$sdev^2)/sum(pc.weather$sdev^2), type = 'b', ylim=c(0,1))
abline(h = 0.9)
summary(pc.weather)
# se ci accontentassimo di 2 componenti avremmo il 76% della variabilità totale
#spiegata da queste
#aggiungendo la terza componente abbiamo un grande incremento dal punto di vista di
#variabilità spiegata (cosa che non succede se aggiungo anche la quarta)
#fermanoci alla terza spieghiamo il 94% della variabilità totale (ottimo)
barplot(pc.weather$sdev^2, pc.weather$sdev^2, pc.weather$sdev^2)
pc.weather$sdev
# se ci accontentassimo di 2 componenti avremmo il 76% della variabilità totale
#spiegata da queste
#aggiungendo la terza componente abbiamo un grande incremento dal punto di vista di
#variabilità spiegata (cosa che non succede se aggiungo anche la quarta)
#fermanoci alla terza spieghiamo il 94% della variabilità totale (ottimo)
barplot(pc.weather$sdev[1:3]^2)
# se ci accontentassimo di 2 componenti avremmo il 76% della variabilità totale
#spiegata da queste
#aggiungendo la terza componente abbiamo un grande incremento dal punto di vista di
#variabilità spiegata (cosa che non succede se aggiungo anche la quarta)
#fermanoci alla terza spieghiamo il 94% della variabilità totale (ottimo)
head(pc.weather$scores)
pc.weather <- subset(pc.weather, select = c(1,2,3))
help("subset")
pc.weather <- subset(pc.weather, select = 1,2,3)
pc.weather <- subset(pc.weather, select = 1:3)
pc.weather.sc <- subset(pc.weather$scores, select = 1:3)
pc.weather.sc
rm(pc.weather.sc)
pc.weather$sdev
pc.weather$sdev[1:3]^2
help("barplot")
barplot(pc.weather$sdev[1:3]^2, names.arg = pc.weather$sdev[1:3]^2)
#d) The measurements for the 1st of August are the following: mean temperature 30◦ C, min temperature 23◦ C, max
#temperature 36◦ C, dew point 22◦ C, humidity 65%, visibility 19km, mean wind 5km/h and max wind 15km/h.
#Project the new datum on the reduced space identified at point (c).
pc.weather$loadings
#d) The measurements for the 1st of August are the following: mean temperature 30◦ C, min temperature 23◦ C, max
#temperature 36◦ C, dew point 22◦ C, humidity 65%, visibility 19km, mean wind 5km/h and max wind 15km/h.
#Project the new datum on the reduced space identified at point (c).
eigensV <- pc.weather$loadings
eigensV
#d) The measurements for the 1st of August are the following: mean temperature 30◦ C, min temperature 23◦ C, max
#temperature 36◦ C, dew point 22◦ C, humidity 65%, visibility 19km, mean wind 5km/h and max wind 15km/h.
#Project the new datum on the reduced space identified at point (c).
eigensV <- pc.weather$loadings[,1:3]
eigensV
x.new <- c(30, 23, 36, 22, 65, 19, 5, 15)
pc1.new <- rbind(eigensV[,1])%*%x.new
pc1.new
pc2.new <- rbind(eigensV[,2])%*%x.new
pc3.new <- rbind(eigensV[,3])%*%x.new
pc2.new
pc3.new
#a) Perform a statistical test of level 95% to verify if the mean measurements on the led bulbs produced by the two
#brands differ. State the model assumptions required to perform the test and verify them.
candle <- read.table(('candle.txt'))
head(candle)
sunshine <- read.table(('sunshine.txt'))
head(sunshine)
m.c <- colMeans(candle)
m.s <- colMeans(sunshine)
m.diff <- m.c -m.s
n.c <- dim(candle)[1]
n.s <- dim(candle)[1]
cfr <- ((n.c+n.s-2)*p/(n.c+n.s-1-p)) * qf(1-0.05, p, n.c+n.s-1-p)
p <- 2
cfr <- ((n.c+n.s-2)*p/(n.c+n.s-1-p)) * qf(1-0.05, p, n.c+n.s-1-p)
#a) Perform a statistical test of level 95% to verify if the mean measurements on the led bulbs produced by the two
#brands differ. State the model assumptions required to perform the test and verify them.
candle <- read.table(('candle.txt'))
head(candle)
sunshine <- read.table(('sunshine.txt'))
head(sunshine)
m.c <- colMeans(candle)
m.s <- colMeans(sunshine)
n.c <- dim(candle)[1]
n.s <- dim(candle)[1]
p <- 2
m.diff <- m.c -m.s
cfr <- ((n.c+n.s-2)*p/(n.c+n.s-1-p)) * qf(1-0.05, p, n.c+n.s-1-p)
m.diff
Spooled <- (cov(candle)*(n.c-1) +cov(sunshine)*(n.s-1))/(n.c+n.s-2)
T2 <- (1/n.s + 1/n.c)^(-1) * rbind(m.diff) %*% solve(Spooled) %*% cbind(m.diff)
cfr <- ((n.c+n.s-2)*p/(n.c+n.s-1-p)) * qf(1-0.05, p, n.c+n.s-1-p)
T2 > cfr
#verify the assumptions
load("/home/rose/Desktop/Applied Statistics/Lab 5/mcshapiro.test.RData")
#verify the assumptions
load("/home/rose/Desktop/Applied Statistics/Lab 5/mcshapiro.test.RData")
mcshapiro.test(candle)
mcshapiro.test(candle)$pvalue
mcshapiro.test(sunshine)$pvalue
help("bartlett.test")
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50)), dummy)
cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50))
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50)), dummy)
cov(candle)
cov(sunshine)
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50)), dummy)
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(as.matrix(cbind(rbind(candle,sunshine), dummy= rep(c(0,1)), each = 50)), dummy)
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(as.matrix(cbind(rbind(candle,sunshine), dummy= rep(c(0,1)), each = 50)), dummy)
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(as.matrix(cbind(rbind(candle,sunshine), rep(c(0,1)), each = 50)), dummy)
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50)), dummy)
bartlett_test <- bartlett.test(list(candle, sunshine))
list(candle, sunshine)
bartlett_test <- bartlett.test(list(candle[,-1], sunshine[,-1]))
head(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50)))
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50)), dummy)
bartlett_test <- bartlett.test(list(candle[,-1], sunshine[,-1]))
bartlett_test
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50))[,-1], dummy)
bartlett_test <- bartlett.test(list(candle[,-1], sunshine[,-1]))
bartlett.test(list(candle[,-1], sunshine[,-1]))
#questo secondo me è giusto e ha senso vedendo le 2 matrici covarianza
cov(candle)
cov(sunshine)
#b) Compute and report the p-value of the test at point (a).
pval <- pf(T2*((n.c+n.s-2)*p/(n.c+n.s-1-p))^(-1),p, n.s+n.c-1-p)
pval
help(pf)
T2*((n.c+n.s-2)*p/(n.c+n.s-1-p))^(-1)
#b) Compute and report the p-value of the test at point (a).
pval <- pf(T2*((n.c+n.s-2)*p/(n.c+n.s-1-p))^(-1),p, n.s+n.c-1-p)
pval
bci1 <- c(
m.diff[1] - qt(1-0.05,n.s+n.c-2) * sqrt(Spooled[1,1]/(n.s+n.c)),
m.diff[1] + qt(1-0.05,n.s+n.c-2) * sqrt(Spooled[1,1]/(n.s+n.c))
)
#c) Interpret the results of the test at point (a) through two Bonferroni intervals of global level 95% for appropriate
#differences in the mean. Comment the result.
k <- 2
bci1 <- c(
m.diff[1] - qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[1,1]/(n.s+n.c)),
m.diff[1] + qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[1,1]/(n.s+n.c))
)
bci2 <- c(
m.diff[2] - qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[2,2]/(n.s+n.c)),
m.diff[2] + qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[2,2]/(n.s+n.c))
)
bci1
bci2
m.diff
#d) Is there statistical evidence to state that, at level 95%, the decrease in brightness between the two measurements
#of the led bulbs produced by Candle Inc. is in mean higher than the one of the led bulbs produced by Sunshine
#Corp.?
decr.c <- m.c[1] - m.c[2]
#d) Is there statistical evidence to state that, at level 95%, the decrease in brightness between the two measurements
#of the led bulbs produced by Candle Inc. is in mean higher than the one of the led bulbs produced by Sunshine
#Corp.?
decr.c <- m.c[1] - m.c[2]
decr.s <- m.s[1] - m.s[2]
decr.c
decr.s
decr.diff <- decr.c - decr.s
decr.diff
#d) Is there statistical evidence to state that, at level 95%, the decrease in brightness between the two measurements
#of the led bulbs produced by Candle Inc. is in mean higher than the one of the led bulbs produced by Sunshine
#Corp.?
decr.c <- candle[1] - candle[2]
mean(decr.c)
mean(decr.c)
decr.c
#d) Is there statistical evidence to state that, at level 95%, the decrease in brightness between the two measurements
#of the led bulbs produced by Candle Inc. is in mean higher than the one of the led bulbs produced by Sunshine
#Corp.?
decr.c <- candle[2] - candle[3]
candle
#d) Is there statistical evidence to state that, at level 95%, the decrease in brightness between the two measurements
#of the led bulbs produced by Candle Inc. is in mean higher than the one of the led bulbs produced by Sunshine
#Corp.?
decr.c <- candle[,2] - candle[,3]
candle[,2]
candle[,3]
dim(candle)
#d) Is there statistical evidence to state that, at level 95%, the decrease in brightness between the two measurements
#of the led bulbs produced by Candle Inc. is in mean higher than the one of the led bulbs produced by Sunshine
#Corp.?
decr.c <- candle[,1] - candle[,2]
decr.c
m.decr.c <- m.c[1] - m.c[2]
m.decr.s <- m.s[1] - m.s[2]
mean(decr.c)
m.decr.c <- m.c[1] - m.c[2]
m.decr.c
decr.s <- sunshine[,1] - sunshine[,2]
m.decr.c <- m.c[1] - m.c[2]
m.decr.s <- m.s[1] - m.s[2]
decr.diff <- (m.decr.c - m.decr.s)
decr.diff <- decr.c - decr.s
decr.diff
m.decr.diff <- (m.decr.c - m.decr.s)
decr.diff
shapiro.test(decr.diff)
#a) Perform a statistical test of level 95% to verify if the mean measurements on the led bulbs produced by the two
#brands differ. State the model assumptions required to perform the test and verify them.
candle <- read.table(('candle.txt'))
head(candle)
sunshine <- read.table(('sunshine.txt'))
head(sunshine)
m.c <- colMeans(candle)
m.s <- colMeans(sunshine)
n.c <- dim(candle)[1]
n.s <- dim(candle)[1]
Spooled <- (cov(candle)*(n.c-1) +cov(sunshine)*(n.s-1))/(n.c+n.s-2)
p <- 2
m.diff <- m.c -m.s
cfr <- ((n.c+n.s-2)*p/(n.c+n.s-1-p)) * qf(1-0.05, p, n.c+n.s-1-p)
T2 <- (1/n.s + 1/n.c)^(-1) * rbind(m.diff) %*% solve(Spooled) %*% cbind(m.diff)
T2 > cfr
#verify the assumptions
load("/home/rose/Desktop/Applied Statistics/Lab 5/mcshapiro.test.RData")
mcshapiro.test(candle)$pvalue
mcshapiro.test(sunshine)$pvalue
#i do not reject the hypothesis of normality at level 5% or 10%
bartlett.test(cbind(rbind(candle,sunshine), dummy= rep(c(0,1), each = 50))[,-1], dummy)
bartlett.test(list(candle[,-1], sunshine[,-1]))
#questo secondo me è giusto e ha senso vedendo le 2 matrici covarianza
cov(candle)
cov(sunshine)
#b) Compute and report the p-value of the test at point (a).
pval <- pf(T2*((n.c+n.s-2)*p/(n.c+n.s-1-p))^(-1),p, n.s+n.c-1-p)
pval
#c) Interpret the results of the test at point (a) through two Bonferroni intervals of global level 95% for appropriate
#differences in the mean. Comment the result.
k <- 2
bci1 <- c(
m.diff[1] - qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[1,1]/(n.s+n.c)),
m.diff[1] + qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[1,1]/(n.s+n.c))
)
bci2 <- c(
m.diff[2] - qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[2,2]/(n.s+n.c)),
m.diff[2] + qt(1-0.05/(2*k),n.s+n.c-2) * sqrt(Spooled[2,2]/(n.s+n.c))
)
bci1
bci2
m.diff
#d) Is there statistical evidence to state that, at level 95%, the decrease in brightness between the two measurements
#of the led bulbs produced by Candle Inc. is in mean higher than the one of the led bulbs produced by Sunshine
#Corp.?
decr.c <- candle[,1] - candle[,2]
decr.s <- sunshine[,1] - sunshine[,2]
decr.diff <- decr.c - decr.s
shapiro.test(decr.diff) #normale in quanto c.l. di variabili normali
m.decr.c <- m.c[1] - m.c[2]
m.decr.s <- m.s[1] - m.s[2]
m.decr.diff <- (m.decr.c - m.decr.s)
t2 <- (n.s+ n.c) * (m.decr.diff^2)/var(decr.diff)
t2 <- (m.decr.diff)/sqrt(var(decr.diff)/(n.s+ n.c))
cfr.t <- qt(1-0.05, n.s+n.c-1)
t2 >cfr.t
Spooled
cov(rbind(candle,sunshine))
pval
pval
#b) Compute and report the p-value of the test at point (a).
pval <- pf(T2/((n.c+n.s-2)*p/(n.c+n.s-1-p)),p, n.s+n.c-1-p)
pval
