setwd("C:/Users/Michele/Desktop/Applied Statistics Labs/Lab 3")

tourists <- read.table('tourists.txt', header=T)
head(tourists)

tourists.label <- tourists[, 1:2] #cut categorical features
tourists <- tourists[, -(1:2)]

dev.off()
par(mar=rep(8,4))
boxplot(tourists, las=2, col='gold') #identify which variables have more variab

#_______________________________________________________________________________
##### PCA
pc.tourists <- princomp(tourists, scores=T)
pc.tourists #see the PCs
summary(pc.tourists) #see the PCs + Cumulative

pc.tourists$sd #PCs manually
pc.tourists$sd^2/sum(pc.tourists$sd^2) #% of Variance manually
cumsum(pc.tourists$sd^2)/sum(pc.tourists$sd^2) #Cumulative manually

#loadings (coefficients of the linear combination of the original 
#           variables that defines each principal component)

load.tour <- pc.tourists$loadings
load.tour

x11()
par(mfrow = c(3,1)) #loads first 6 PCs
for(i in 1:3) barplot(load.tour[,i], ylim = c(-1, 1))

#_______________________________________________________________________________
##### INTERPRETATION
#First PCs: weighted average of the number of nights in 3,4 stars hotel and residences
#Second PCs: contrast between the number of nights in 3 and 4 stars hotel
#Third PC: residences

#The first PC explains more than 98% of the total variability -> NORMALIZE


#_______________________________________________________________________________
##### PCA NORMALIZED DATASET
tourists.sd <- scale(tourists)
tourists.sd <- data.frame(tourists.sd)

pc.tourists <- princomp(tourists.sd, scores=T)
summary(pc.tourists) #now the first PC explains 89%

load.tour <- pc.tourists$loadings
load.tour

x11()
par(mar = c(2,2,2,1), mfrow=c(3,1))
for(i in 1:3)barplot(load.tour[,i], ylim = c(-1, 1), main=paste('Loadings PC ',i,sep=''))

#_______________________________________________________________________________
##### INTERPRETATION 2
# In this case, the first PC represents an average of the number of nights spent in 
# all the types of hotels and residences, taken with very similar weights.
# The second PC contrasts the more expensive solutions (4,5 stars hotels and residences)
# against the cheap solutions (1,2 stars hotels and B&B)

# High PC1: general high flow of tourists
# Low PC1: general low flow of tourists 
# High PC2: high flow for expensive solutions, low flow for cheap solutions
# Low PC2: low flow for expensive solutions, high flow for cheap solutions

#scores
scores.tourists <- pc.tourists$scores
scores.tourists

#_______________________________________________________________________________
##### PCA on an another DATASET 
##### new stuff: 
# original variability vs score variability
# projection on the rotated space

rm(list = ls())
food <- read.table('Food.txt', header=T)

food.sd <- scale(food)
food.sd <- data.frame(food.sd)

pc.food <- princomp(food.sd, scores=T)
summary(pc.food)

scores.food <- pc.food$scores
load.food <- pc.food$loadings

# variability of the original variables vs variability of the scores
x11()
layout(matrix(c(1,2),2))
boxplot(food.sd, las=2, col='gold', main='Original variables')
scores.food <- data.frame(scores.food)
boxplot(scores.food, las=2, col='gold', main='Principal components')

# projection on the space generated by the first k principal components
x11()
par(mfrow=c(2,5))
matplot(t(food.sd), type='l', main = 'Data', ylim=range(food.sd))
meanF <- colMeans(food.sd)
matplot(meanF, type='l', main = 'First 0 PCs', lwd=2, ylim=range(food.sd))
projection <- matrix(meanF, dim(food.sd)[[1]], dim(food.sd)[[2]], byrow=T)
for(i in 1:8)
{
  projection <- projection + scores.food[,i] %*% t(load.food[,i])
  matplot(t(projection), type='l', main = paste('First', i, 'PCs'), ylim=range(food.sd))
  matplot(meanF, type='l', lwd=2, add=T)
}

#_______________________________________________________________________________
##### DIMENSIONALITY REDUCTION
library(rgl)
options(rgl.printRglwidget = TRUE)

mu  <- c(0, 2, 3)
sig <- rbind(c(9, 1, 1), c(1, 4, 1), c(1, 1, 1))
nobs <- 100
X <- rmvnorm(nobs, mu, sig)
M <- colMeans(X)
S <- cov(X)
PC <- princomp(X)

# original dataset
open3d()                    # open a new device
points3d(X, asp=1, size=4)  # plot the points
axes3d()                    # add the axes
plot3d(ellipse3d(S, centre=M, level= 9/10), alpha=0.15, add=TRUE) # add the ellipsoid



# "0" principal component: a point (the mean)
open3d()
points3d(X, asp=1, size=4)
axes3d()

points3d(t(M), col='red', size=6)

for(i in 1:100)
  lines3d(rbind(X[i,], M))

# first principal component: a line
open3d()
points3d(X, asp=1, size=4)
axes3d()

PC1 <- NULL
for(i in 1:nobs) {
  PC1 <- rbind(PC1, PC$loadings[,1]*PC$scores[i,1] + M)
}
points3d(PC1, col='red', size=6)

for(i in 1:nobs) {
  lines3d(rbind(X[i,], PC1[i,]), col='blue')
}

lines3d(rbind(M + 2*PC$sdev[1] * PC$loadings[,1], M - 2*PC$sdev[1] * PC$loadings[,1]),
        col='forestgreen',lwd=2)

# 1st and 2nd principal components: a plane
open3d()
points3d(X, asp=1, size=4)
axes3d()

PC12 <- NULL
for(i in 1:nobs) {
  PC12 <- rbind(PC12, PC$loadings[,1]*PC$scores[i,1] + PC$loadings[,2]*PC$scores[i,2] + M)
}
points3d(PC12, col='red', size=6)

for(i in 1:nobs) {
  lines3d(rbind(X[i,], PC12[i,]),col='blue')
}

lines3d(rbind(M + 2*PC$sdev[1] * PC$loadings[,1], M - 2*PC$sdev[1] * PC$loadings[,1]),
        col='forestgreen',lwd=2) 
lines3d(rbind(M + 2*PC$sdev[2] * PC$loadings[,2], M - 2*PC$sdev[2] * PC$loadings[,2]),
        col='forestgreen',lwd=2) 

# 1st, 2nd, 3rd principal components: the entire space

open3d()
points3d(X, asp=1, size=4)
axes3d()

PC123 <- NULL
for(i in 1:nobs) {
  PC123 <- rbind(PC123, PC$loadings[,1]*PC$scores[i,1] + PC$loadings[,2]*PC$scores[i,2]
                 + PC$loadings[,3]*PC$scores[i,3] + M)
}
points3d(PC123, col='red', size=6)

for(i in 1:nobs) {
  lines3d(rbind(X[i,], PC123[i,]),col='blue')
}

lines3d(rbind(M + 2*PC$sdev[1] * PC$loadings[,1], M - 2*PC$sdev[1] * PC$loadings[,1]),
        col='forestgreen',lwd=2) 
lines3d(rbind(M + 2*PC$sdev[2] * PC$loadings[,2], M - 2*PC$sdev[2] * PC$loadings[,2]),
        col='forestgreen',lwd=2) 
lines3d(rbind(M + 2*PC$sdev[3] * PC$loadings[,3], M - 2*PC$sdev[3] * PC$loadings[,3]),
        col='forestgreen',lwd=2)

#_______________________________________________________________________________
##### Example: 
##### Question (c) of Problem 3 of the 29/06/2010 exam
## The file scotland.txt collects the number of residents in Scotland, according
## to the last census of 2001, divided by age and county. Assume the data 
## associated with different counties to be independent and identically distributed,
## and assume the data corresponding to different age ranges to be dependent.
## Perform a dimensionality reduction of the dataset through a principal component
## analysis and interpret the obtained components

age <- read.table('scotland.txt', header=T)
head(age)
dim(age)

x11()
pairs(age, pch=19)
boxplot(age)
matplot(t(age), type='l', xlab='Age', ylab='Number of Residents', lty=1, col=rainbow(33), las=1)

S <- cov(age)
image(S, asp=1)

var.gen <- det(S)
var.tot <- sum( diag(S) )

# PCA (on the covariance matrix)
pc.age <- princomp(age, scores=T)
pc.age
summary(pc.age)

# Explained variance
x11()
layout(matrix(c(2,3,1,3),2,byrow=T))
barplot(pc.age$sdev^2, las=2, main='Principal Components', ylab='Variances')
barplot(sapply(age,sd)^2, las=2, main='Original variables', ylab='Variances')
plot(cumsum(pc.age$sdev^2)/sum(pc.age$sde^2), type='b', axes=F, xlab='number of components', ylab='contribution to the total variance', ylim=c(0,1))
abline(h=1, col='blue')
abline(h=0.8, lty=2, col='blue')
box()
axis(2,at=0:10/10,labels=0:10/10)
axis(1,at=1:ncol(age),labels=1:ncol(age),las=2)

# Scores
scores.age <- pc.age$scores
scores.age

layout(matrix(c(1,2),2))
boxplot(age, las=2, col='gold', main='Original variables')
scores.age <- data.frame(scores.age)
boxplot(scores.age, las=2, col='gold', main='Principal components')

load.age    <- pc.age$loadings
load.age

x11()
par(mar = c(1,4,0,2), mfrow = c(3,1))
for(i in 1:3)barplot(load.age[,i], ylim = c(-1, 1))

x11()
plot(scores.age[,1],scores.age[,2],type="n",xlab="pc1",ylab="pc2", asp=1)
text(scores.age[,1],scores.age[,2],dimnames(age)[[1]], cex=0.7)

biplot(pc.age)

# Projection on the space generated by the k-th principal component
x11(width=18, height=7)
par(mfrow=c(2,3))
#matplot(t(age), type='l', main = 'Data', ylim=range(age))
meanA <- colMeans(age)
matplot(meanA, type='l', main = '0 PC', lwd=2, ylim=range(age))
for(i in 1:5)
{
  projection <- matrix(meanA, dim(age)[[1]], dim(age)[[2]], byrow=T) + scores.age[,i] %*% t(load.age[,i])
  matplot(t(projection), type='l', main = paste(i, 'PC'), ylim=range(age))
  matplot(meanA, type='l', lwd=2, add=T)
}

# Projection on the space generated by the first k principal components
x11(width=18, height=7)
par(mfrow=c(2,3))
#matplot(t(age), type='l', main = 'Data', ylim=range(age))
meanA <- colMeans(age)
matplot(meanA, type='l', main = '0 PC', lwd=2, ylim=range(age))
projection <- matrix(meanA, dim(age)[[1]], dim(age)[[2]], byrow=T)
for(i in 1:5)
{
  projection <- projection + scores.age[,i] %*% t(load.age[,i])
  matplot(t(projection), type='l', main = paste('First', i, 'PCs'), ylim=range(age))
  matplot(meanA, type='l', lwd=2, add=T)
}

